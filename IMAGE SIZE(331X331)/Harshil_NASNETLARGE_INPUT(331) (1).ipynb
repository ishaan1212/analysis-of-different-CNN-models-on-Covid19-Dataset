{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pZp7YGm8Ew0R"},"outputs":[],"source":["from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D, AveragePooling2D\n","from keras.layers.merge import concatenate\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Flatten, Dense\n","from keras.layers import Activation\n","from keras.layers import BatchNormalization\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","from tensorflow import keras\n","\n","from keras.models import Sequential\n","from keras.layers.core import Flatten, Dense, Dropout\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n","from tensorflow.keras.optimizers import SGD\n","import cv2, numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ntochG3Ew0U","executionInfo":{"status":"ok","timestamp":1641484190367,"user_tz":-330,"elapsed":24243,"user":{"displayName":"ISHAN SACHDEVA (RA1911003010039)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05371051040517831980"}},"outputId":"e04fba5f-d50c-4842-ae3d-841c3e705f11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dasRGarBEw0V","executionInfo":{"status":"ok","timestamp":1641484210188,"user_tz":-330,"elapsed":11029,"user":{"displayName":"ISHAN SACHDEVA (RA1911003010039)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05371051040517831980"}},"outputId":"a935ade9-f6e1-491d-c6a6-c6e33b8bb08e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5171 images belonging to 3 classes.\n","Found 1292 images belonging to 3 classes.\n"]}],"source":["train_datagen_with_aug = ImageDataGenerator(rescale=1./255,\n","                                   horizontal_flip=True,\n","                                   shear_range=0.2,\n","                                   zoom_range=[0.2,0.5],\n","                                   width_shift_range = 0.3,\n","                                   height_shift_range = 0.3,\n","                                   validation_split=0.2)\n","\n","train_generator = train_datagen_with_aug.flow_from_directory(\n","    r'/content/drive/My Drive/X-Ray Images Dataset for research project-20211204T084221Z-001',\n","    target_size=(331, 331),\n","    batch_size=32,\n","    # color_mode='grayscale',\n","    class_mode='categorical',\n","    subset='training'\n","    ) # set as training data\n","\n","validation_generator = train_datagen_with_aug.flow_from_directory(\n","    r'/content/drive/My Drive/X-Ray Images Dataset for research project-20211204T084221Z-001', # same directory as training data\n","    target_size=(331, 331),\n","    batch_size=32,\n","    # color_mode='grayscale',\n","    class_mode='categorical',\n","    subset='validation'\n","    ) # set as validation data\n","\n","input_img = Input(shape=(331, 331, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sxb-BMnVEw0V","executionInfo":{"status":"ok","timestamp":1641484224080,"user_tz":-330,"elapsed":12535,"user":{"displayName":"ISHAN SACHDEVA (RA1911003010039)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05371051040517831980"}},"outputId":"d3af4921-4940-4922-a36e-a2eda62db9c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n","343613440/343610240 [==============================] - 2s 0us/step\n","343621632/343610240 [==============================] - 2s 0us/step\n"]}],"source":["from keras.applications import nasnet\n","\n","NASNET_LARGE = Sequential()\n","\n","nasnetlarge_model =keras.applications.nasnet.NASNetLarge(\n","    input_shape=(331,331,3), include_top=False, weights='imagenet',\n","    pooling=('max'), classes=3\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4loVLVUgEw0W","outputId":"db1e3c05-b8d8-42e3-fd69-c40a42ffbea6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," NASNet (Functional)         (None, 4032)              84916818  \n","                                                                 \n"," flatten (Flatten)           (None, 4032)              0         \n","                                                                 \n"," dense (Dense)               (None, 512)               2064896   \n","                                                                 \n"," dense_1 (Dense)             (None, 3)                 1539      \n","                                                                 \n","=================================================================\n","Total params: 86,983,253\n","Trainable params: 2,066,435\n","Non-trainable params: 84,916,818\n","_________________________________________________________________\n","Epoch 1/25\n"]}],"source":["for layer in nasnetlarge_model.layers:\n","    layer.trainable = False\n","    \n","NASNET_LARGE.add(nasnetlarge_model)\n","NASNET_LARGE.add(Flatten())\n","NASNET_LARGE.add(Dense(512,activation='relu'))\n","NASNET_LARGE.add(Dense(3, activation='softmax'))\n","\n","NASNET_LARGE.summary()\n","\n","Adam = keras.optimizers.Adam(learning_rate=0.001)\n","NASNET_LARGE.compile(optimizer=Adam, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","graph = NASNET_LARGE.fit(train_generator, epochs=25, validation_data = validation_generator)\n","\n","graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6D77ZG7dEw0W"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","fig1 = plt.gcf()\n","\n","plt.plot(graph.history['accuracy'])\n","plt.plot(graph.history['val_accuracy'])\n","\n","# plt.axis(ymin=0.4, ymax=1)\n","plt.grid()\n","\n","plt.title('NASNet Large Accuracy Input: 224x224 for COVID-19 Dataset')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epochs')\n","plt.legend(['train','validation'])\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nE-sItAWEw0X"},"outputs":[],"source":["max_acc = max(graph.history['val_accuracy'])\n","\n","print('The highest accuracy achieved using NASNet Large Model with input 224x224 is', max_acc*100)"]}],"metadata":{"interpreter":{"hash":"7804450ba48a012a076ecacf1eec884416c5029de8377612e26af9477f1cf541"},"kernelspec":{"display_name":"Python 3.8.12 64-bit ('gpu_env_1': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"orig_nbformat":4,"colab":{"name":"Harshil_NASNETLARGE_INPUT(331) (1).ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}