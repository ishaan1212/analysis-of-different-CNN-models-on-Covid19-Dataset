{"cells":[{"cell_type":"code","execution_count":null,"id":"aa520b05","metadata":{"id":"aa520b05"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"id":"e272a03d","metadata":{"id":"e272a03d"},"outputs":[],"source":["from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D, AveragePooling2D\n","from keras.layers.merge import concatenate\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Flatten, Dense\n","from keras.layers import Activation\n","from keras.layers import BatchNormalization\n","from keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"code","execution_count":null,"id":"a23c7e0c","metadata":{"id":"a23c7e0c"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers.core import Flatten, Dense, Dropout\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n","from tensorflow.keras.optimizers import SGD\n","import cv2, numpy as np"]},{"cell_type":"code","execution_count":null,"id":"edc6a302","metadata":{"id":"edc6a302","outputId":"69e24b16-4ec1-41a5-d88a-9f6ee01a4aa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5171 images belonging to 3 classes.\n","Found 1292 images belonging to 3 classes.\n"]}],"source":["train_datagen_with_aug = ImageDataGenerator(rescale=1./255,\n","                                   horizontal_flip=True,\n","                                   shear_range=0.2,\n","                                   zoom_range=[0.2,0.5],\n","                                   width_shift_range = 0.3,\n","                                   height_shift_range = 0.3,\n","                                   validation_split=0.2)\n","\n","train_generator = train_datagen_with_aug.flow_from_directory(\n","    r'D:\\BARANIDHARAN SIR PROJECT\\X-Ray Images Dataset for research project-20211204T084221Z-001',\n","    target_size=(331, 331),\n","    batch_size=32,\n","    # color_mode='grayscale',\n","    class_mode='categorical',\n","    subset='training'\n","    ) # set as training data\n","\n","validation_generator = train_datagen_with_aug.flow_from_directory(\n","    r'D:\\BARANIDHARAN SIR PROJECT\\X-Ray Images Dataset for research project-20211204T084221Z-001', # same directory as training data\n","    target_size=(331, 331),\n","    batch_size=32,\n","    # color_mode='grayscale',\n","    class_mode='categorical',\n","    subset='validation'\n","    ) # set as validation data\n","\n","input_img = Input(shape=(331, 331, 3))"]},{"cell_type":"code","execution_count":null,"id":"e31ab6b8","metadata":{"id":"e31ab6b8"},"outputs":[],"source":["from tensorflow.keras.applications import resnet50"]},{"cell_type":"code","execution_count":null,"id":"88553d9a","metadata":{"id":"88553d9a","outputId":"30ad785b-2f29-4747-b23a-c389f00eb924"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 7s 0us/step\n"]}],"source":["RESNET_50_MODEL = Sequential()\n","\n","resnet50_model = keras.applications.resnet50.ResNet50(\n","    include_top=False, weights='imagenet', input_tensor=None,\n","    input_shape=(331,331,3),classes=3, pooling='avg'\n",")"]},{"cell_type":"code","execution_count":null,"id":"c8df05bb","metadata":{"id":"c8df05bb"},"outputs":[],"source":["# we run this command to prevent the resnet model from re-learning the parameters again, this saves on time\n","for layer in resnet50_model.layers:\n","    layer.trainable = False "]},{"cell_type":"code","execution_count":null,"id":"69360a7e","metadata":{"id":"69360a7e"},"outputs":[],"source":["RESNET_50_MODEL.add(resnet50_model)\n","RESNET_50_MODEL.add(Flatten())\n","RESNET_50_MODEL.add(Dense(512,activation='relu'))\n","RESNET_50_MODEL.add(Dense(3, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"id":"0ea55719","metadata":{"id":"0ea55719","outputId":"b014378d-e822-4955-9d1d-11e2440479ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Functional)        (None, 2048)              23587712  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               1049088   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 1539      \n","=================================================================\n","Total params: 24,638,339\n","Trainable params: 1,050,627\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"]}],"source":["RESNET_50_MODEL.summary()"]},{"cell_type":"code","execution_count":null,"id":"b0c24442","metadata":{"id":"b0c24442"},"outputs":[],"source":["Adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n","RESNET_50_MODEL.compile(optimizer=Adam, loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"a7ca2035","metadata":{"id":"a7ca2035","outputId":"0253ce05-a5f4-48a5-dbd2-14097c41a148"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","162/162 [==============================] - 1378s 9s/step - loss: 1.2475 - accuracy: 0.3864 - val_loss: 1.2321 - val_accuracy: 0.3870\n","Epoch 2/25\n","162/162 [==============================] - 1353s 8s/step - loss: 1.1015 - accuracy: 0.4042 - val_loss: 1.0775 - val_accuracy: 0.3870\n","Epoch 3/25\n","162/162 [==============================] - 1361s 8s/step - loss: 1.0851 - accuracy: 0.3959 - val_loss: 1.0860 - val_accuracy: 0.4125\n","Epoch 4/25\n","162/162 [==============================] - 1276s 8s/step - loss: 1.0798 - accuracy: 0.4071 - val_loss: 1.1088 - val_accuracy: 0.2810\n","Epoch 5/25\n","162/162 [==============================] - 1261s 8s/step - loss: 1.0744 - accuracy: 0.4297 - val_loss: 1.0603 - val_accuracy: 0.3870\n","Epoch 6/25\n","162/162 [==============================] - 1321s 8s/step - loss: 1.0686 - accuracy: 0.4218 - val_loss: 1.0765 - val_accuracy: 0.3870\n","Epoch 7/25\n","162/162 [==============================] - 1353s 8s/step - loss: 1.0620 - accuracy: 0.4340 - val_loss: 1.0635 - val_accuracy: 0.3909\n","Epoch 8/25\n","162/162 [==============================] - 1348s 8s/step - loss: 1.0603 - accuracy: 0.4285 - val_loss: 1.0505 - val_accuracy: 0.3885\n","Epoch 9/25\n","162/162 [==============================] - 1313s 8s/step - loss: 1.0590 - accuracy: 0.4384 - val_loss: 1.0491 - val_accuracy: 0.4226\n","Epoch 10/25\n","162/162 [==============================] - 1386s 9s/step - loss: 1.0498 - accuracy: 0.4518 - val_loss: 1.0399 - val_accuracy: 0.4837\n","Epoch 11/25\n","162/162 [==============================] - 1317s 8s/step - loss: 1.0462 - accuracy: 0.4624 - val_loss: 1.0286 - val_accuracy: 0.5046\n","Epoch 12/25\n","162/162 [==============================] - 1279s 8s/step - loss: 1.0475 - accuracy: 0.4722 - val_loss: 1.0386 - val_accuracy: 0.4582\n","Epoch 13/25\n","162/162 [==============================] - 1303s 8s/step - loss: 1.0631 - accuracy: 0.4382 - val_loss: 1.0376 - val_accuracy: 0.5449\n","Epoch 14/25\n","162/162 [==============================] - 1272s 8s/step - loss: 1.0478 - accuracy: 0.4630 - val_loss: 1.0330 - val_accuracy: 0.4985\n","Epoch 15/25\n","162/162 [==============================] - 1286s 8s/step - loss: 1.0330 - accuracy: 0.4922 - val_loss: 1.0214 - val_accuracy: 0.5155\n","Epoch 16/25\n","162/162 [==============================] - 1234s 8s/step - loss: 1.0314 - accuracy: 0.4763 - val_loss: 1.0758 - val_accuracy: 0.3870\n","Epoch 17/25\n","162/162 [==============================] - 1235s 8s/step - loss: 1.0450 - accuracy: 0.4713 - val_loss: 1.0201 - val_accuracy: 0.5147\n","Epoch 18/25\n","162/162 [==============================] - 1230s 8s/step - loss: 1.0320 - accuracy: 0.4866 - val_loss: 1.0182 - val_accuracy: 0.4559\n","Epoch 19/25\n","162/162 [==============================] - 1229s 8s/step - loss: 1.0164 - accuracy: 0.5154 - val_loss: 1.0002 - val_accuracy: 0.5526\n","Epoch 20/25\n","162/162 [==============================] - 1230s 8s/step - loss: 1.0089 - accuracy: 0.5177 - val_loss: 1.0193 - val_accuracy: 0.4567\n","Epoch 21/25\n","162/162 [==============================] - 1248s 8s/step - loss: 1.0139 - accuracy: 0.4974 - val_loss: 1.0003 - val_accuracy: 0.4892\n","Epoch 22/25\n","162/162 [==============================] - 1271s 8s/step - loss: 1.0003 - accuracy: 0.5219 - val_loss: 0.9838 - val_accuracy: 0.5070\n","Epoch 23/25\n","162/162 [==============================] - 1275s 8s/step - loss: 1.0037 - accuracy: 0.5146 - val_loss: 0.9709 - val_accuracy: 0.5681\n","Epoch 24/25\n","162/162 [==============================] - 1280s 8s/step - loss: 0.9874 - accuracy: 0.5314 - val_loss: 0.9714 - val_accuracy: 0.5418\n","Epoch 25/25\n","162/162 [==============================] - 1271s 8s/step - loss: 0.9883 - accuracy: 0.5405 - val_loss: 0.9479 - val_accuracy: 0.5743\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x24253243a48>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["RESNET_50_MODEL.fit(train_generator, epochs=25, validation_data = validation_generator)"]},{"cell_type":"code","execution_count":null,"id":"e2009a08","metadata":{"id":"e2009a08","outputId":"2b115f34-bf72-4192-bea1-8900a9790f29"},"outputs":[{"ename":"TypeError","evalue":"'History' object is not subscriptable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-16-f8f6428c89cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRESNET_50_MODEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRESNET_50_MODEL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"]},{"data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<Figure size 720x360 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":[""]},{"cell_type":"code","execution_count":null,"id":"c944015a","metadata":{"id":"c944015a","outputId":"d12b82a2-c0a2-4a19-cfa4-4932a57b0133"},"outputs":[{"ename":"NameError","evalue":"name 'graph' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-13-127f3a8c8757>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The highest accuracy achived using the NASNet Mobile model is\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_acc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'graph' is not defined"]}],"source":[""]},{"cell_type":"code","execution_count":null,"id":"99dffa9a","metadata":{"id":"99dffa9a"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"Ishan_RESNET50_INPUT(331).ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}