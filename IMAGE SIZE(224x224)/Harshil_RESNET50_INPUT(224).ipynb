{"cells":[{"cell_type":"code","execution_count":null,"id":"aa520b05","metadata":{"id":"aa520b05"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"id":"e272a03d","metadata":{"id":"e272a03d"},"outputs":[],"source":["from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D, AveragePooling2D\n","from keras.layers.merge import concatenate\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Flatten, Dense\n","from keras.layers import Activation\n","from keras.layers import BatchNormalization\n","from keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"code","execution_count":null,"id":"a23c7e0c","metadata":{"id":"a23c7e0c"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers.core import Flatten, Dense, Dropout\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n","from tensorflow.keras.optimizers import SGD\n","import cv2, numpy as np"]},{"cell_type":"code","execution_count":null,"id":"edc6a302","metadata":{"id":"edc6a302","outputId":"c8208225-3c24-4dc4-c3c0-aff52bb9cbbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5121 images belonging to 3 classes.\n","Found 1278 images belonging to 3 classes.\n"]}],"source":["train_datagen_with_aug = ImageDataGenerator(rescale=1./255,\n","                                   horizontal_flip=True,\n","                                   shear_range=0.2,\n","                                   zoom_range=[0.2,0.5],\n","                                   width_shift_range = 0.3,\n","                                   height_shift_range = 0.3,\n","                                   validation_split=0.2)\n","\n","train_generator = train_datagen_with_aug.flow_from_directory(\n","    r'D:\\My Work\\Baranidharan Sir Research\\cnn_xrays_images',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    # color_mode='grayscale',\n","    class_mode='categorical',\n","    subset='training'\n","    ) # set as training data\n","\n","validation_generator = train_datagen_with_aug.flow_from_directory(\n","    r'D:\\My Work\\Baranidharan Sir Research\\cnn_xrays_images', # same directory as training data\n","    target_size=(224, 224),\n","    batch_size=32,\n","    # color_mode='grayscale',\n","    class_mode='categorical',\n","    subset='validation'\n","    ) # set as validation data\n","\n","input_img = Input(shape=(224, 224, 3))"]},{"cell_type":"code","execution_count":null,"id":"e31ab6b8","metadata":{"id":"e31ab6b8"},"outputs":[],"source":["from tensorflow.keras.applications import resnet50"]},{"cell_type":"code","execution_count":null,"id":"88553d9a","metadata":{"id":"88553d9a"},"outputs":[],"source":["RESNET_50_MODEL = Sequential()\n","\n","resnet50_model = keras.applications.resnet50.ResNet50(\n","    include_top=False, weights='imagenet', input_tensor=None,\n","    input_shape=(224,224,3),classes=3, pooling='avg'\n",")"]},{"cell_type":"code","execution_count":null,"id":"c8df05bb","metadata":{"id":"c8df05bb"},"outputs":[],"source":["# we run this command to prevent the resnet model from re-learning the parameters again, this saves on time\n","for layer in resnet50_model.layers:\n","    layer.trainable = False "]},{"cell_type":"code","execution_count":null,"id":"69360a7e","metadata":{"id":"69360a7e"},"outputs":[],"source":["RESNET_50_MODEL.add(resnet50_model)\n","RESNET_50_MODEL.add(Flatten())\n","RESNET_50_MODEL.add(Dense(512,activation='relu'))\n","RESNET_50_MODEL.add(Dense(3, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"id":"0ea55719","metadata":{"id":"0ea55719","outputId":"1d00e44d-ab88-4337-97fe-8e32bcd15c5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Functional)        (None, 2048)              23587712  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               1049088   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 1539      \n","=================================================================\n","Total params: 24,638,339\n","Trainable params: 1,050,627\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"]}],"source":["RESNET_50_MODEL.summary()"]},{"cell_type":"code","execution_count":null,"id":"b0c24442","metadata":{"id":"b0c24442"},"outputs":[],"source":["Adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n","RESNET_50_MODEL.compile(optimizer=Adam, loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"a7ca2035","metadata":{"id":"a7ca2035","outputId":"e668b1f0-8951-42c3-f3d4-f02ffcf90699"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","161/161 [==============================] - 493s 3s/step - loss: 1.1312 - accuracy: 0.4153 - val_loss: 1.0840 - val_accuracy: 0.3858\n","Epoch 2/25\n","161/161 [==============================] - 409s 3s/step - loss: 1.0856 - accuracy: 0.4263 - val_loss: 1.0549 - val_accuracy: 0.4390\n","Epoch 3/25\n","161/161 [==============================] - 409s 3s/step - loss: 1.0527 - accuracy: 0.4585 - val_loss: 1.0224 - val_accuracy: 0.5203\n","Epoch 4/25\n","161/161 [==============================] - 396s 2s/step - loss: 1.0468 - accuracy: 0.4704 - val_loss: 1.0177 - val_accuracy: 0.5329\n","Epoch 5/25\n","161/161 [==============================] - 395s 2s/step - loss: 1.0324 - accuracy: 0.4774 - val_loss: 1.0241 - val_accuracy: 0.4085\n","Epoch 6/25\n","161/161 [==============================] - 395s 2s/step - loss: 1.0202 - accuracy: 0.4968 - val_loss: 0.9877 - val_accuracy: 0.5477\n","Epoch 7/25\n","161/161 [==============================] - 395s 2s/step - loss: 1.0132 - accuracy: 0.5040 - val_loss: 1.0012 - val_accuracy: 0.5149\n","Epoch 8/25\n","161/161 [==============================] - 398s 2s/step - loss: 0.9962 - accuracy: 0.5212 - val_loss: 0.9933 - val_accuracy: 0.4984\n","Epoch 9/25\n","161/161 [==============================] - 396s 2s/step - loss: 1.0007 - accuracy: 0.5138 - val_loss: 1.0049 - val_accuracy: 0.4742\n","Epoch 10/25\n","161/161 [==============================] - 414s 3s/step - loss: 0.9935 - accuracy: 0.5167 - val_loss: 0.9980 - val_accuracy: 0.4883\n","Epoch 11/25\n","161/161 [==============================] - 434s 3s/step - loss: 0.9713 - accuracy: 0.5438 - val_loss: 1.0335 - val_accuracy: 0.4531\n","Epoch 12/25\n","161/161 [==============================] - 483s 3s/step - loss: 1.0266 - accuracy: 0.4882 - val_loss: 1.0033 - val_accuracy: 0.5133\n","Epoch 13/25\n","161/161 [==============================] - 468s 3s/step - loss: 0.9916 - accuracy: 0.5349 - val_loss: 0.9725 - val_accuracy: 0.5516\n","Epoch 14/25\n","161/161 [==============================] - 498s 3s/step - loss: 0.9969 - accuracy: 0.5138 - val_loss: 1.0599 - val_accuracy: 0.4249\n","Epoch 15/25\n","161/161 [==============================] - 480s 3s/step - loss: 0.9769 - accuracy: 0.5411 - val_loss: 0.9921 - val_accuracy: 0.4977\n","Epoch 16/25\n","161/161 [==============================] - 464s 3s/step - loss: 0.9949 - accuracy: 0.5259 - val_loss: 0.9664 - val_accuracy: 0.5501\n","Epoch 17/25\n","161/161 [==============================] - 487s 3s/step - loss: 0.9795 - accuracy: 0.5384 - val_loss: 0.9516 - val_accuracy: 0.5391\n","Epoch 18/25\n","161/161 [==============================] - 464s 3s/step - loss: 0.9908 - accuracy: 0.5269 - val_loss: 0.9642 - val_accuracy: 0.5282\n","Epoch 19/25\n","161/161 [==============================] - 446s 3s/step - loss: 0.9668 - accuracy: 0.5444 - val_loss: 0.9413 - val_accuracy: 0.5595\n","Epoch 20/25\n","161/161 [==============================] - 460s 3s/step - loss: 0.9892 - accuracy: 0.5237 - val_loss: 0.9504 - val_accuracy: 0.5556\n","Epoch 21/25\n","161/161 [==============================] - 433s 3s/step - loss: 0.9758 - accuracy: 0.5390 - val_loss: 0.9844 - val_accuracy: 0.5102\n","Epoch 22/25\n","161/161 [==============================] - 425s 3s/step - loss: 0.9761 - accuracy: 0.5419 - val_loss: 0.9454 - val_accuracy: 0.5376\n","Epoch 23/25\n","161/161 [==============================] - 425s 3s/step - loss: 0.9604 - accuracy: 0.5532 - val_loss: 0.9950 - val_accuracy: 0.5117\n","Epoch 24/25\n","161/161 [==============================] - 426s 3s/step - loss: 0.9734 - accuracy: 0.5349 - val_loss: 0.9608 - val_accuracy: 0.5430\n","Epoch 25/25\n","161/161 [==============================] - 425s 3s/step - loss: 0.9633 - accuracy: 0.5425 - val_loss: 0.9264 - val_accuracy: 0.5642\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x18bf7112c48>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["RESNET_50_MODEL.fit(train_generator, epochs=25, validation_data = validation_generator)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"name":"Harshil_RESNET50_INPUT(224).ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}